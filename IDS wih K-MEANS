#--Langkah 1 - Mengumpulkan Data 

ids <- read.csv("C:/Users/ASUS/Downloads/ids lama.csv", sep=";", stringsAsFactors=TRUE)
View(ids)
# mengimport data dari file dan menampilkan dataset di rstudio, disini data terdiri dari 42 kolom dan 22.455 baris

#--Melihat visualisasi distribusi data 

boxplot(ids)
# distribusi data belum baik, maka dari itu kita harus melakukan normalisasi data terlebih dahulu

#--Agar nilai mutlak 0 tidak dikira NA

ids[is.na(ids)] <- 0
# pada dataset ini, ada beberapa kolom yang isi datanya "0", tetapi bukan data kosong dan memang nilainya 0. 
maka kita submit syntax ini untuk menginisialisasi nilai 0 bukan data NA 

#--Baca data dan periksa strukturnya

str(ids)
# syntax ini bertujuan untuk melihat tipe dari struktur data, karena kita ingin menyesuaikan dengan k-means nanti yang mengaharuskan data bertipe "numerik"

#--Fungsi normalisasi khusus

normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}
# menormalisasi data dengan metode max min agar rentang nilai dari dataset lebih baik

#--Terapkan normalisasi ke seluruh data frame

ids_norm <- as.data.frame(lapply(ids, normalize))
str(ids_norm)
# melakukan normalisasi pada setiap elemen dari objek ids dan menyimpan hasilnya dalam bentuk data frame baru yang disebut ids_norm.

#--Konfirmasikan bahwa rentangnya sekarang antara nol dan satu

summary(ids_norm$labels)
# Kesimpulan yang dapat diambil adalah distribusi nilai dalam kolom labels memiliki variasi, dengan rata-rata sekitar 0.4630. Kuartil pertama dan kuartil ketiga yang relatif dekat menunjukkan bahwa sebagian besar data terkonsentrasi di sekitar nilai tersebut. Nilai maksimum adalah 1.0000, yang menunjukkan adanya variasi yang signifikan antara nilai minimum dan maksimum.

#--Dibandingkan dengan minimum dan maksimum aslinya

boxplot(ids_norm)
# data ids sudah terdistribusi normal

#--Langkah 2 - CORRELATION

Faktor_Berpengaruh <- cor(ids_norm[c("duration", "protocol_type", "service", "flag", "src_bytes", 
                                "dst_bytes", "land", "wrong_fragment", "urgent", "hot", 
                                "num_failed_logins", "logged_in", "num_compromised", 
                                "root_shell", "su_attempted", "num_root", 
                                "num_file_creations", "num_shells", "num_access_files", 
                                 "is_host_login", "is_guest_login", 
                                "count", "srv_count", "serror_rate", 
                                "srv_serror_rate", "rerror_rate", "srv_rerror_rate", 
                                "same_srv_rate", "diff_srv_rate", "srv_diff_host_rate", 
                                "dst_host_count", "dst_host_srv_count", 
                                "dst_host_same_srv_rate", "dst_host_diff_srv_rate", 
                                "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate", 
                                "dst_host_serror_rate", "dst_host_srv_serror_rate", 
                                "dst_host_rerror_rate", "dst_host_srv_rerror_rate", "labels")],
                          use = "complete.obs")

print(Faktor_Berpengaruh)

# karena variabel dari data ids cukup banyak, maka akan dilakukan filterisasi dengan melihat korelasi terlebih dahulu

#--Melihat nilai korelasi antara variabel dengan kolom "labels"

Faktor_Berpengaruh["duration", "labels"]
Faktor_Berpengaruh["protocol_type", "labels"]
Faktor_Berpengaruh["service", "labels"]
Faktor_Berpengaruh["flag", "labels"]
Faktor_Berpengaruh["src_bytes", "labels"]
Faktor_Berpengaruh["dst_bytes", "labels"]
Faktor_Berpengaruh["land", "labels"]
Faktor_Berpengaruh["wrong_fragment", "labels"]
Faktor_Berpengaruh["urgent", "labels"]
Faktor_Berpengaruh["hot", "labels"]
Faktor_Berpengaruh["num_failed_logins", "labels"]
Faktor_Berpengaruh["logged_in", "labels"]
Faktor_Berpengaruh["num_compromised", "labels"]
Faktor_Berpengaruh["root_shell", "labels"]
Faktor_Berpengaruh["su_attempted", "labels"]
Faktor_Berpengaruh["num_root", "labels"]
Faktor_Berpengaruh["num_file_creations", "labels"]
Faktor_Berpengaruh["num_shells", "labels"]
Faktor_Berpengaruh["num_access_files", "labels"]
Faktor_Berpengaruh["is_host_login", "labels"]
Faktor_Berpengaruh["is_guest_login", "labels"]
Faktor_Berpengaruh["count", "labels"]
Faktor_Berpengaruh["srv_count", "labels"]
Faktor_Berpengaruh["serror_rate", "labels"]
Faktor_Berpengaruh["srv_serror_rate", "labels"]
Faktor_Berpengaruh["rerror_rate", "labels"]
Faktor_Berpengaruh["srv_rerror_rate", "labels"]
Faktor_Berpengaruh["same_srv_rate", "labels"]
Faktor_Berpengaruh["diff_srv_rate", "labels"]
Faktor_Berpengaruh["srv_diff_host_rate", "labels"]
Faktor_Berpengaruh["dst_host_count", "labels"]
Faktor_Berpengaruh["dst_host_srv_count", "labels"]
Faktor_Berpengaruh["dst_host_same_srv_rate", "labels"]
Faktor_Berpengaruh["dst_host_diff_srv_rate", "labels"]
Faktor_Berpengaruh["dst_host_same_src_port_rate", "labels"]
Faktor_Berpengaruh["dst_host_srv_diff_host_rate", "labels"]
Faktor_Berpengaruh["dst_host_serror_rate", "labels"]
Faktor_Berpengaruh["dst_host_srv_serror_rate", "labels"]
Faktor_Berpengaruh["dst_host_rerror_rate", "labels"]
Faktor_Berpengaruh["dst_host_srv_rerror_rate", "labels"]
```
# mendapatkan nilai korelasi dari perbandingan variabel dengan kolom "labels"

#--Mendapatkan daftar nama kolom dari dataset 

column_names <- colnames(ids_norm)
print(column_names)
# hal ini dilakukan untuk mempermudah pembuatan set data baru yaitu dengan menggunakan nama/header kolom

#--Menjadikan 6 kolom dengan nilai korelasi tertinggi menjadi satu dataset

selected_columns <- c("srv_count", "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", "is_guest_login", "wrong_fragment", "count", "labels")
# agar proses analisis berjalan dengan lebih cepat, maka 6 kolom dengan tingkat korelasi tertinggi dengan label dipilih dan dijadikan satu set data baru

#--Memilih kolom-kolom yang diinginkan dari dataset

ids_new <- ids_norm[, column_names %in% selected_columns]
# memilih kolom-kolom tertentu dari ids_norm berdasarkan kolom-kolom yang terdapat dalam vektor selected_columns

#--Menampilkan dataset baru

print(ids_new)
str(ids_new)

#-- Langkah 3 - Mulai analisis k-means

library(factoextra)
library(cluster)
# packages ini merupakan packages yang diperlukan jika ingin menganalisis menggunakan algoritma k-means

#--Membentuk cluster (sesuaikan dengan cluster yg dipilih)

cluster <- kmeans(ids_new,5)
# pada analisis kali ini, kita ingin membuat 5 kluster 

#--Visualisasi cluster

fviz_cluster(cluster,ids_new) 
# ini adalah hasil visualisasi menggunakan algoritma k-means yang dibuat menjadi 5 cluster dari data ids_new

#--interpretasi dan penamaan cluster

cluster$centers
k5 = kmeans(ids_new, centers = 5, nstart = 25)

#--Disini untuk melihat sebaran tiap cluster ada berapa banyak

print(k5)

#--Mengembalikan dari data normalisasi ke data sebelum normalisasi

final=data.frame(ids, k5$cluster)
View(final)

#--Menggunakan fungsi dist() untuk menghitung jarak Euclidean

distances <- dist(cluster$centers, method = "euclidean")
print(distances)
# Semakin kecil jarak, semakin dekat entitas tersebut. 
